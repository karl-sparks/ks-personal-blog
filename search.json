[
  {
    "objectID": "posts/ai-resume-builder-project-plan/index.html",
    "href": "posts/ai-resume-builder-project-plan/index.html",
    "title": "Hello Resume Builder",
    "section": "",
    "text": "As a first AI project, I thought it fitting that I build an AI to build resumes.\nMy objectives with this project are:\n\nEnhance my skills in developing a comprehensive application from start to finish, including deployment.\nCreate a practical and valuable tool as the project outcome.\n\nTo achieve these objectives, I explored various approaches. Initially, I considered using a straightforward Google Colab notebook, which would effectively address objective 2 by providing the necessary functionality. However, it would not fulfill objective 1.\nTo address both objectives comprehensively, I will develop a more intricate yet robust application using cloud technologies. A simplified diagram is provided below, outlining the primary components:\n\n\n\nSimple Architecture\n\n\nThe main components are:\n\nServerless Backend: This component will be constructed using AWS Lambda, and its primary function will be to facilitate API access to the underlying model.\n\nThe advantages of utilizing serverless backends include scalability for the final app in a resource-efficient manner, as they separate the resource intensive aspects from the continuously running server.\nThe logic of the underlying model will be further refined in proof-of-concept (POC) notebooks. It is likely to break down the resume generation process into multiple components, utilizing ChatGPT to build each part. Additional context will be sourced from the user and/or job advertisements. Another model may be employed to assess the quality of the output.\n\nResume Builder App: This component will primarily focus on the user interface (UI) and will likely be built using Streamlit for efficiency. Its role will be to gather user data and present the generated resumes to users.\nChatGPT: The core model for resume generation will be ChatGPT by OpenAI, which will be accessed through OpenAI’s API.\nVarious datasets stored in AWS: Depending on the progress of the proof-of-concept (POC) work, additional datasets will be collected and stored in AWS. These datasets may encompass:\n\nJob ads\nResumes\nLinkedin profiles etc\n\n\nI anticipate that this approach will serve as a valuable opportunity for honing my skills in the development and deployment of machine learning applications while simultaneously delivering a practical tool. Throughout this endeavor, I intend to maintain a flexible approach, allowing the final design and choice of tools to evolve based on insights gained from experimentation and proof-of-concept work. I will periodically document my progress towards achieving these goals by sharing POC updates on this blog."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Karl Sparks",
    "section": "",
    "text": "I am a AI enthusiast and data expert. I am currently a Principal Analyst at the Australian Prudential Regulation Authority where I generate insights and create data tools.\nPreviously, I worked at the Reserve Bank of Australia where I maintained the RBA’s banks’ funding model and undertook economic and financial research."
  },
  {
    "objectID": "index.html#projects",
    "href": "index.html#projects",
    "title": "Karl Sparks",
    "section": "Projects",
    "text": "Projects\n\nAI Resume Builder"
  },
  {
    "objectID": "index.html#articles",
    "href": "index.html#articles",
    "title": "Karl Sparks",
    "section": "Articles",
    "text": "Articles\n\nBank Fees in Australia\nBank Fees in Australia During the COVID-19 Pandemic"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Proof of Concept\n\n\n\n\n\n\n\nresume-builder\n\n\npoc\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2023\n\n\nKarl Sparks\n\n\n\n\n\n\n  \n\n\n\n\nHello Resume Builder\n\n\n\n\n\n\n\nresume-builder\n\n\ndesign\n\n\n\n\n\n\n\n\n\n\n\nOct 2, 2023\n\n\nKarl Sparks\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/first-poc/index.html",
    "href": "posts/first-poc/index.html",
    "title": "Proof of Concept",
    "section": "",
    "text": "Key Findings from Proof of Concept:\n\nLLMs for Resume Building: LLMs, specifically GPT-4, proved effective in summarizing information for resume creation.\nContext Sensitivity: Output quality was sensitive to both context provided and the prompt template used.\nImprovement Aspects: To enhance output quality, three key aspects were identified:\n\n\nValidation Mechanism: Essential for testing model changes and identifying better-performing versions, potentially using another LLM for validation.\nFeedback Mechanism: Vital for refining the model and validation process based on user-detected errors and issues.\nStructured Output: Implementing structured output to ensure consistency in the generated resumes.\n\n\nProof of concept\nFirst, I used ChatGPT-4 to make sure the use case is workable.\nAlthough, GPT-4 is one of the most expensive LLMs available, I decided to go with GPT-4 because it is generally the best performing model for most use cases. If I can’t get my use case working well with GPT-4 than I would unlikely be able to get it working with another model. The cost is also not that large at the proof of concept stage, although would be significant if scaled up.\nFor this proof of concept I will use Langchain to access GPT-4 and create the prompts. This API conveniently lets me set up the prompt in components based on a template. This lets met feed in additional information piece by piece, such as job description and resume experience. This functionality will be important when it comes to generallising this model to other jobs/resumes etc.\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport openai\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\n\nllm = ChatOpenAI(model_name=\"gpt-4\")\n\nI create the prompt template below. When creating the template I experimented with a few different options to improve the outcome. This included using common recommendations such as including “lets think step by step”, and specifying the output format.\n\ntemplate = \"\"\"You are helping create a resume for a job seeker (the candidate).\n\nUse the following job description and information on the candidate background when answering the below question.\n\nMake sure you do not make specific reference to skills or achievements that are not mentioned in the background.\n\nThe candidate is applying for a job as a {job_title} at a {company_name} with the job description as follows:\n{job_description}\n\nCandidate background: \n{context}\n\nQuestion: Create a resume for the candedate. Make sure to include measureable metrics where possible.\n\nAnswer: Let's think step by step.\"\"\"\n\nprompt = PromptTemplate(template=template, input_variables=[\"context\", \"job_title\", \"company_name\", \"job_description\"])\n\nllm_chain = LLMChain(prompt=prompt, llm=llm)\n\njob_title = \"Machine Learning Engineer\"\n\ncompany_name = \"Machinify\"\n\njob_description = \"\"\"\nMachinify is a revolutionary healthcare software company with a mission to ensure that patients get the right medical treatment, at the right time, at the right price. Our cloud-based Machinify AI platform leverages the latest advances in machine learning, large language models, data analytics, and cloud processing to solve previously intractable problems, transforming healthcare administration and payment operations.\n\nWe are seeking an ML Engineer to join our AI focused healthcare startup. Our team has deployed models that check for anomalies in medical claims, predict the trajectory of care of a particular patient and the next likely treatment and even “read and understand” medical record documents using state-of-the-art NLP and computer vision techniques to assist clinicians. There are many more such problems to be solved. So if you are looking for a place where you can apply your expertise in AI/ML to solve real problems and make a difference in an industry that impacts millions of lives while accelerating your career, you’ll love Machinify. We are seeking a Sr Machine Learning Scientist to join our team.\n\nWhat you’ll do:\nAdvance Machinify’s capabilities to model and understand medical decisions which will power a range of products in the claims processing space. \nMake thoughtful decisions around which methods/algorithms are likely to work well in solving the business problem at hand\nConsider the quality of the available input data and build robust systems that will work well in the presence of noise/errors\nMeasure the model output in practical real-world settings and iterate your approach \nLearn about the healthcare industry and become an expert over time\n\nWhat You Bring:\nYou enjoy solving real-world business problems by developing, from scratch, ML models and deploying them in production - and have been doing that successfully for a while. \nYou are comfortable measuring and optimizing the direct business impact of your work. \nYou are interested in learning about the healthcare industry and helping us improve the care millions of people receive. \nYou are scrappy, and love solving hard problems that matter. \nYou are experienced with SQL, handling large-scale data, and are comfortable with at least one programming language (Python, R, etc.). \nYou have experience building ML models using modern ML approaches like Neural Nets or Tree-ensembles from scratch for new applications - making decisions relating to which supervised labels to use, the metric to optimize for, and the features likely to be useful. \nYou are a critical thinker who can be strategic without losing attention to detail. \nYou are comfortable taking the initiative and owning projects from start to finish. \nYou can build positive relationships based on trust and value delivered. \n\nThe base salary for this position will vary based on an array of factors unique to each candidate such as qualifications, years and depth of experience, skill set, certifications, etc. The base salary range for this role is $180k-250k. We are hiring for different seniorities, and our Recruiting team will let you know if you qualify for a different role/range. Salary is one component of the total compensation package, which includes meaningful equity, excellent healthcare, flexible time off, and other benefits and perks.\n\nEqual Employment Opportunity at Machinify\n\nMachinify is committed to hiring talented and qualified individuals with diverse backgrounds for all of its positions. Machinify believes that the gathering and celebration of unique backgrounds, qualities, and cultures enriches the workplace.\n\"\"\"\n\ncontext = \"\"\"\nWork Experience:\n  - Principal Analyst for the Austrlian Prudential Regulation Authority.\n    - Extensively uses R and SQL to analyse data and produce reports.\n    - Has a strong understanding of the Australian financial system.\n    - Created R packages to automate the production of reports.\n    - Created new automated reports to highlight the difference between old and new capital frameworks for everyone of the 114 reporting ADIs.\n  - Senior Analyst for the Reserve Bank of Australia.\n    - Used R to build and maintain models to monitor and forecast banks' funding costs.\n    - Undertook economic and financial research to support the Bank's monetary policy and payment regulation functions.\n    - Liaising with external and internal stakeholders for their expert opinions on different bank funding markets, drawing this all together to provide a comprehensive overview of funding conditions.\n    - Monitoring of the quantity and price of bank funding sources such as deposits, bonds, securitisation and money markets using various data sources.\n    - Analysing data collected through the Economic and Financial Statistics (EFS) collection. Including liaising with reporting institutions on reporting standards and data quality issues, and preparing data for publication.\n    - Used R and SQL to build and maintain models to monitor and forecast banks' funding costs. to analyse data and forecasting the impact of changes in banks' funding conditions on average funding costs.\n\"\"\"\n\nThe above prompt and context will create the below response from ChatGPT-4.\n\nanswer = llm_chain.run({\"context\": context, \"job_title\": job_title, \"company_name\": company_name, \"job_description\": job_description})\n\nprint(answer)\n\nResume\n\nName: [Candidate's name]\nContact Information: [Candidate's Email, Phone, LinkedIn]\n\nObjective: Motivated and experienced analyst, leveraging expertise in data analysis, machine learning, and healthcare industry to drive improvements in patient care and administrative efficiency. \n\nWork Experience:\n\nPrincipal Analyst, Australian Prudential Regulation Authority\n- Utilized R and SQL extensively for data analysis and report generation, enhancing the understanding of the Australian financial system.\n- Automated report production through the creation of R packages, increasing efficiency and accuracy.\n- Developed novel automated reports to differentiate between old and new capital frameworks for all 114 reporting ADIs, providing crucial insights for policy making.\n\nSenior Analyst, Reserve Bank of Australia\n- Built and maintained models using R and SQL to monitor and forecast banks' funding costs, contributing to the accuracy of financial planning.\n- Conducted economic and financial research to support the Bank's monetary policy and payment regulation functions.\n- Liaised with a variety of stakeholders for expert opinions on different bank funding markets, culminating in a comprehensive overview of funding conditions.\n- Monitored the quantity and price of bank funding sources using various data sources to forecast changes in banks' funding conditions on average funding costs.\n- Handled data collected through the Economic and Financial Statistics (EFS) collection, liaising with reporting institutions on reporting standards and data quality issues, and preparing data for publication.\n\nSkills:\n- Proficient in R and SQL.\n- Extensive experience in data analysis and financial modeling.\n- Excellent communication skills, with a track record of effectively liaising with both internal and external stakeholders.\n- Proven ability to automate report production and increase efficiency.\n- Strong problem-solving and critical-thinking abilities.\n\nEducation:\n[Relevant degree(s) and institution(s)]\n\nCertifications:\n[Relevant certifications]\n\nLanguages:\n- English\n- [Any other languages the candidate speaks]\n\nReferences:\nAvailable upon request"
  }
]